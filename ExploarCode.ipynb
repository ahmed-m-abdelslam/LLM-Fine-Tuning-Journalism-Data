{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fa8d019",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5e54bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.48.3Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached transformers-4.48.3-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from transformers==4.48.3) (3.20.3)\n",
      "Collecting huggingface-hub<1.0,>=0.24.0 (from transformers==4.48.3)\n",
      "  Downloading huggingface_hub-0.36.2-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from transformers==4.48.3) (2.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from transformers==4.48.3) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from transformers==4.48.3) (6.0.3)\n",
      "Collecting regex!=2019.12.17 (from transformers==4.48.3)\n",
      "  Using cached regex-2026.1.15-cp310-cp310-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from transformers==4.48.3) (2.32.5)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers==4.48.3)\n",
      "  Using cached tokenizers-0.21.4-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers==4.48.3)\n",
      "  Using cached safetensors-0.7.0-cp38-abi3-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting tqdm>=4.27 (from transformers==4.48.3)\n",
      "  Using cached tqdm-4.67.3-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.48.3) (2025.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.48.3) (4.15.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from tqdm>=4.27->transformers==4.48.3) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from requests->transformers==4.48.3) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from requests->transformers==4.48.3) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from requests->transformers==4.48.3) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from requests->transformers==4.48.3) (2026.1.4)\n",
      "Using cached transformers-4.48.3-py3-none-any.whl (9.7 MB)\n",
      "Downloading huggingface_hub-0.36.2-py3-none-any.whl (566 kB)\n",
      "   ---------------------------------------- 0.0/566.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/566.4 kB ? eta -:--:--\n",
      "   ------------------ --------------------- 262.1/566.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 566.4/566.4 kB 1.4 MB/s  0:00:00\n",
      "Using cached tokenizers-0.21.4-cp39-abi3-win_amd64.whl (2.5 MB)\n",
      "Using cached regex-2026.1.15-cp310-cp310-win_amd64.whl (277 kB)\n",
      "Using cached safetensors-0.7.0-cp38-abi3-win_amd64.whl (341 kB)\n",
      "Using cached tqdm-4.67.3-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, safetensors, regex, huggingface-hub, tokenizers, transformers\n",
      "\n",
      "   ---------------------------------------- 0/6 [tqdm]\n",
      "   ------------- -------------------------- 2/6 [regex]\n",
      "   -------------------- ------------------- 3/6 [huggingface-hub]\n",
      "   -------------------- ------------------- 3/6 [huggingface-hub]\n",
      "   -------------------- ------------------- 3/6 [huggingface-hub]\n",
      "   -------------------- ------------------- 3/6 [huggingface-hub]\n",
      "   -------------------- ------------------- 3/6 [huggingface-hub]\n",
      "   -------------------- ------------------- 3/6 [huggingface-hub]\n",
      "   -------------------------- ------------- 4/6 [tokenizers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   ---------------------------------------- 6/6 [transformers]\n",
      "\n",
      "Successfully installed huggingface-hub-0.36.2 regex-2026.1.15 safetensors-0.7.0 tokenizers-0.21.4 tqdm-4.67.3 transformers-4.48.3\n",
      "Collecting datasets==3.2.0\n",
      "  Using cached datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from datasets==3.2.0) (3.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from datasets==3.2.0) (2.0.1)\n",
      "Collecting pyarrow>=15.0.0 (from datasets==3.2.0)\n",
      "  Using cached pyarrow-23.0.0-cp310-cp310-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets==3.2.0)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets==3.2.0)\n",
      "  Using cached pandas-2.3.3-cp310-cp310-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from datasets==3.2.0) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from datasets==3.2.0) (4.67.3)\n",
      "Collecting xxhash (from datasets==3.2.0)\n",
      "  Using cached xxhash-3.6.0-cp310-cp310-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets==3.2.0)\n",
      "  Using cached multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets==3.2.0)\n",
      "  Using cached fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets==3.2.0)\n",
      "  Using cached aiohttp-3.13.3-cp310-cp310-win_amd64.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from datasets==3.2.0) (0.36.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from datasets==3.2.0) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from datasets==3.2.0) (6.0.3)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp->datasets==3.2.0)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp->datasets==3.2.0)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp->datasets==3.2.0)\n",
      "  Using cached async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets==3.2.0)\n",
      "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets==3.2.0)\n",
      "  Using cached frozenlist-1.8.0-cp310-cp310-win_amd64.whl.metadata (21 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets==3.2.0)\n",
      "  Using cached multidict-6.7.1-cp310-cp310-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets==3.2.0)\n",
      "  Using cached propcache-0.4.1-cp310-cp310-win_amd64.whl.metadata (14 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets==3.2.0)\n",
      "  Using cached yarl-1.22.0-cp310-cp310-win_amd64.whl.metadata (77 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from multidict<7.0,>=4.5->aiohttp->datasets==3.2.0) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets==3.2.0) (3.11)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from requests>=2.32.2->datasets==3.2.0) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from requests>=2.32.2->datasets==3.2.0) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from requests>=2.32.2->datasets==3.2.0) (2026.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from tqdm>=4.66.3->datasets==3.2.0) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from pandas->datasets==3.2.0) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets==3.2.0)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets==3.2.0)\n",
      "  Using cached tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets==3.2.0) (1.17.0)\n",
      "Using cached datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Using cached multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Using cached aiohttp-3.13.3-cp310-cp310-win_amd64.whl (456 kB)\n",
      "Using cached async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Using cached multidict-6.7.1-cp310-cp310-win_amd64.whl (46 kB)\n",
      "Using cached yarl-1.22.0-cp310-cp310-win_amd64.whl (86 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Using cached frozenlist-1.8.0-cp310-cp310-win_amd64.whl (43 kB)\n",
      "Using cached propcache-0.4.1-cp310-cp310-win_amd64.whl (41 kB)\n",
      "Using cached pyarrow-23.0.0-cp310-cp310-win_amd64.whl (27.5 MB)\n",
      "Using cached pandas-2.3.3-cp310-cp310-win_amd64.whl (11.3 MB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
      "Using cached xxhash-3.6.0-cp310-cp310-win_amd64.whl (31 kB)\n",
      "Installing collected packages: pytz, xxhash, tzdata, pyarrow, propcache, multidict, fsspec, frozenlist, dill, attrs, async-timeout, aiohappyeyeballs, yarl, pandas, multiprocess, aiosignal, aiohttp, datasets\n",
      "\n",
      "   ----------------------------------------  0/18 [pytz]\n",
      "   ----------------------------------------  0/18 [pytz]\n",
      "   ---- -----------------------------------  2/18 [tzdata]\n",
      "   ---- -----------------------------------  2/18 [tzdata]\n",
      "   ---- -----------------------------------  2/18 [tzdata]\n",
      "   ------ ---------------------------------  3/18 [pyarrow]\n",
      "   ------ ---------------------------------  3/18 [pyarrow]\n",
      "   ------ ---------------------------------  3/18 [pyarrow]\n",
      "   ------ ---------------------------------  3/18 [pyarrow]\n",
      "   ------ ---------------------------------  3/18 [pyarrow]\n",
      "   ------ ---------------------------------  3/18 [pyarrow]\n",
      "   ------ ---------------------------------  3/18 [pyarrow]\n",
      "   ------ ---------------------------------  3/18 [pyarrow]\n",
      "   ------ ---------------------------------  3/18 [pyarrow]\n",
      "   ------ ---------------------------------  3/18 [pyarrow]\n",
      "   ------ ---------------------------------  3/18 [pyarrow]\n",
      "   -------- -------------------------------  4/18 [propcache]\n",
      "  Attempting uninstall: fsspec\n",
      "   -------- -------------------------------  4/18 [propcache]\n",
      "    Found existing installation: fsspec 2025.12.0\n",
      "   -------- -------------------------------  4/18 [propcache]\n",
      "    Uninstalling fsspec-2025.12.0:\n",
      "   -------- -------------------------------  4/18 [propcache]\n",
      "      Successfully uninstalled fsspec-2025.12.0\n",
      "   -------- -------------------------------  4/18 [propcache]\n",
      "   ------------- --------------------------  6/18 [fsspec]\n",
      "   ------------- --------------------------  6/18 [fsspec]\n",
      "   ----------------- ----------------------  8/18 [dill]\n",
      "   -------------------- -------------------  9/18 [attrs]\n",
      "   -------------------------- ------------- 12/18 [yarl]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ---------------------------- ----------- 13/18 [pandas]\n",
      "   ------------------------------- -------- 14/18 [multiprocess]\n",
      "   ----------------------------------- ---- 16/18 [aiohttp]\n",
      "   ----------------------------------- ---- 16/18 [aiohttp]\n",
      "   ------------------------------------- -- 17/18 [datasets]\n",
      "   ------------------------------------- -- 17/18 [datasets]\n",
      "   ------------------------------------- -- 17/18 [datasets]\n",
      "   ------------------------------------- -- 17/18 [datasets]\n",
      "   ---------------------------------------- 18/18 [datasets]\n",
      "\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.13.3 aiosignal-1.4.0 async-timeout-5.0.1 attrs-25.4.0 datasets-3.2.0 dill-0.3.8 frozenlist-1.8.0 fsspec-2024.9.0 multidict-6.7.1 multiprocess-0.70.16 pandas-2.3.3 propcache-0.4.1 pyarrow-23.0.0 pytz-2025.2 tzdata-2025.3 xxhash-3.6.0 yarl-1.22.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting optimum==1.24.0\n",
      "  Using cached optimum-1.24.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: transformers>=4.29 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from optimum==1.24.0) (4.48.3)\n",
      "Requirement already satisfied: torch>=1.11 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from optimum==1.24.0) (2.5.1+cu121)\n",
      "Requirement already satisfied: packaging in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from optimum==1.24.0) (25.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from optimum==1.24.0) (2.0.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.8.0 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from optimum==1.24.0) (0.36.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from huggingface-hub>=0.8.0->optimum==1.24.0) (3.20.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from huggingface-hub>=0.8.0->optimum==1.24.0) (2024.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from huggingface-hub>=0.8.0->optimum==1.24.0) (6.0.3)\n",
      "Requirement already satisfied: requests in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from huggingface-hub>=0.8.0->optimum==1.24.0) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from huggingface-hub>=0.8.0->optimum==1.24.0) (4.67.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from huggingface-hub>=0.8.0->optimum==1.24.0) (4.15.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from torch>=1.11->optimum==1.24.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from torch>=1.11->optimum==1.24.0) (3.1.6)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from torch>=1.11->optimum==1.24.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from sympy==1.13.1->torch>=1.11->optimum==1.24.0) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.8.0->optimum==1.24.0) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from transformers>=4.29->optimum==1.24.0) (2026.1.15)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from transformers>=4.29->optimum==1.24.0) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from transformers>=4.29->optimum==1.24.0) (0.7.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from jinja2->torch>=1.11->optimum==1.24.0) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from requests->huggingface-hub>=0.8.0->optimum==1.24.0) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from requests->huggingface-hub>=0.8.0->optimum==1.24.0) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from requests->huggingface-hub>=0.8.0->optimum==1.24.0) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from requests->huggingface-hub>=0.8.0->optimum==1.24.0) (2026.1.4)\n",
      "Using cached optimum-1.24.0-py3-none-any.whl (433 kB)\n",
      "Installing collected packages: optimum\n",
      "Successfully installed optimum-1.24.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting openai==1.61.0\n",
      "  Using cached openai-1.61.0-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai==1.61.0)\n",
      "  Using cached anyio-4.12.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai==1.61.0)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai==1.61.0)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai==1.61.0)\n",
      "  Downloading jiter-0.13.0-cp310-cp310-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai==1.61.0)\n",
      "  Using cached pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Collecting sniffio (from openai==1.61.0)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from openai==1.61.0) (4.67.3)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from openai==1.61.0) (4.15.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from anyio<5,>=3.5.0->openai==1.61.0) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from anyio<5,>=3.5.0->openai==1.61.0) (3.11)\n",
      "Requirement already satisfied: certifi in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from httpx<1,>=0.23.0->openai==1.61.0) (2026.1.4)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai==1.61.0)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.61.0)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai==1.61.0)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic<3,>=1.9.0->openai==1.61.0)\n",
      "  Using cached pydantic_core-2.41.5-cp310-cp310-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3,>=1.9.0->openai==1.61.0)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from tqdm>4->openai==1.61.0) (0.4.6)\n",
      "Using cached openai-1.61.0-py3-none-any.whl (460 kB)\n",
      "Using cached anyio-4.12.1-py3-none-any.whl (113 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading jiter-0.13.0-cp310-cp310-win_amd64.whl (206 kB)\n",
      "Using cached pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Using cached pydantic_core-2.41.5-cp310-cp310-win_amd64.whl (2.0 MB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: typing-inspection, sniffio, pydantic-core, jiter, h11, distro, annotated-types, pydantic, httpcore, anyio, httpx, openai\n",
      "\n",
      "   ------------- --------------------------  4/12 [h11]\n",
      "   ----------------------- ----------------  7/12 [pydantic]\n",
      "   ----------------------- ----------------  7/12 [pydantic]\n",
      "   ----------------------- ----------------  7/12 [pydantic]\n",
      "   ----------------------- ----------------  7/12 [pydantic]\n",
      "   -------------------------- -------------  8/12 [httpcore]\n",
      "   ------------------------------ ---------  9/12 [anyio]\n",
      "   --------------------------------- ------ 10/12 [httpx]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ------------------------------------ --- 11/12 [openai]\n",
      "   ---------------------------------------- 12/12 [openai]\n",
      "\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.12.1 distro-1.9.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 jiter-0.13.0 openai-1.61.0 pydantic-2.12.5 pydantic-core-2.41.5 sniffio-1.3.1 typing-inspection-0.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting wandbNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached wandb-0.24.2-py3-none-win_amd64.whl.metadata (12 kB)\n",
      "Collecting click>=8.0.1 (from wandb)\n",
      "  Using cached click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
      "  Using cached gitpython-3.1.46-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from wandb) (25.0)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from wandb) (4.5.1)\n",
      "Collecting protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 (from wandb)\n",
      "  Using cached protobuf-6.33.5-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: pydantic<3 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from wandb) (2.12.5)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from wandb) (6.0.3)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from wandb) (2.32.5)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb)\n",
      "  Using cached sentry_sdk-2.52.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.8 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from wandb) (4.15.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from pydantic<3->wandb) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from pydantic<3->wandb) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2026.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from click>=8.0.1->wandb) (0.4.6)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Using cached wandb-0.24.2-py3-none-win_amd64.whl (22.3 MB)\n",
      "Using cached protobuf-6.33.5-cp310-abi3-win_amd64.whl (437 kB)\n",
      "Using cached click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Using cached gitpython-3.1.46-py3-none-any.whl (208 kB)\n",
      "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Using cached sentry_sdk-2.52.0-py2.py3-none-any.whl (435 kB)\n",
      "Installing collected packages: smmap, sentry-sdk, protobuf, click, gitdb, gitpython, wandb\n",
      "\n",
      "   ----- ---------------------------------- 1/7 [sentry-sdk]\n",
      "   ----- ---------------------------------- 1/7 [sentry-sdk]\n",
      "   ----- ---------------------------------- 1/7 [sentry-sdk]\n",
      "   ----- ---------------------------------- 1/7 [sentry-sdk]\n",
      "   ----- ---------------------------------- 1/7 [sentry-sdk]\n",
      "   ----------- ---------------------------- 2/7 [protobuf]\n",
      "   ----------- ---------------------------- 2/7 [protobuf]\n",
      "   ----------------- ---------------------- 3/7 [click]\n",
      "   ---------------------- ----------------- 4/7 [gitdb]\n",
      "   ---------------------------- ----------- 5/7 [gitpython]\n",
      "   ---------------------------------- ----- 6/7 [wandb]\n",
      "   ---------------------------------- ----- 6/7 [wandb]\n",
      "   ---------------------------------- ----- 6/7 [wandb]\n",
      "   ---------------------------------- ----- 6/7 [wandb]\n",
      "   ---------------------------------- ----- 6/7 [wandb]\n",
      "   ---------------------------------- ----- 6/7 [wandb]\n",
      "   ---------------------------------- ----- 6/7 [wandb]\n",
      "   ---------------------------------- ----- 6/7 [wandb]\n",
      "   ---------------------------------- ----- 6/7 [wandb]\n",
      "   ---------------------------------- ----- 6/7 [wandb]\n",
      "   ---------------------------------- ----- 6/7 [wandb]\n",
      "   ---------------------------------- ----- 6/7 [wandb]\n",
      "   ---------------------------------- ----- 6/7 [wandb]\n",
      "   ---------------------------------- ----- 6/7 [wandb]\n",
      "   ---------------------------------- ----- 6/7 [wandb]\n",
      "   ---------------------------------- ----- 6/7 [wandb]\n",
      "   ---------------------------------- ----- 6/7 [wandb]\n",
      "   ---------------------------------- ----- 6/7 [wandb]\n",
      "   ---------------------------------- ----- 6/7 [wandb]\n",
      "   ---------------------------------- ----- 6/7 [wandb]\n",
      "   ---------------------------------- ----- 6/7 [wandb]\n",
      "   ---------------------------------- ----- 6/7 [wandb]\n",
      "   ---------------------------------- ----- 6/7 [wandb]\n",
      "   ---------------------------------- ----- 6/7 [wandb]\n",
      "   ---------------------------------- ----- 6/7 [wandb]\n",
      "   ---------------------------------- ----- 6/7 [wandb]\n",
      "   ---------------------------------- ----- 6/7 [wandb]\n",
      "   ---------------------------------- ----- 6/7 [wandb]\n",
      "   ---------------------------------------- 7/7 [wandb]\n",
      "\n",
      "Successfully installed click-8.3.1 gitdb-4.0.12 gitpython-3.1.46 protobuf-6.33.5 sentry-sdk-2.52.0 smmap-5.0.2 wandb-0.24.2\n",
      "Collecting pydantic_settings\n",
      "  Using cached pydantic_settings-2.12.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: pydantic>=2.7.0 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from pydantic_settings) (2.12.5)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic_settings)\n",
      "  Using cached python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from pydantic_settings) (0.4.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from pydantic>=2.7.0->pydantic_settings) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from pydantic>=2.7.0->pydantic_settings) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from pydantic>=2.7.0->pydantic_settings) (4.15.0)\n",
      "Using cached pydantic_settings-2.12.0-py3-none-any.whl (51 kB)\n",
      "Using cached python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Installing collected packages: python-dotenv, pydantic_settings\n",
      "\n",
      "   -------------------- ------------------- 1/2 [pydantic_settings]\n",
      "   ---------------------------------------- 2/2 [pydantic_settings]\n",
      "\n",
      "Successfully installed pydantic_settings-2.12.0 python-dotenv-1.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting json_repair==0.29.1\n",
      "  Using cached json_repair-0.29.1-py3-none-any.whl.metadata (9.8 kB)\n",
      "Using cached json_repair-0.29.1-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: json_repair\n",
      "Successfully installed json_repair-0.29.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting accelerate==0.26.0\n",
      "  Using cached accelerate-0.26.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from accelerate==0.26.0) (2.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from accelerate==0.26.0) (25.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from accelerate==0.26.0) (7.2.2)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from accelerate==0.26.0) (6.0.3)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from accelerate==0.26.0) (2.5.1+cu121)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from accelerate==0.26.0) (0.36.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from accelerate==0.26.0) (0.7.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from torch>=1.10.0->accelerate==0.26.0) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from torch>=1.10.0->accelerate==0.26.0) (4.15.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from torch>=1.10.0->accelerate==0.26.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from torch>=1.10.0->accelerate==0.26.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from torch>=1.10.0->accelerate==0.26.0) (2024.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from torch>=1.10.0->accelerate==0.26.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate==0.26.0) (1.3.0)\n",
      "Requirement already satisfied: requests in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from huggingface-hub->accelerate==0.26.0) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from huggingface-hub->accelerate==0.26.0) (4.67.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate==0.26.0) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate==0.26.0) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from requests->huggingface-hub->accelerate==0.26.0) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from requests->huggingface-hub->accelerate==0.26.0) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from requests->huggingface-hub->accelerate==0.26.0) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\a1hmm\\anaconda3\\envs\\torchenv\\lib\\site-packages (from requests->huggingface-hub->accelerate==0.26.0) (2026.1.4)\n",
      "Using cached accelerate-0.26.0-py3-none-any.whl (270 kB)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-0.26.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers==4.48.3\n",
    "%pip install datasets==3.2.0\n",
    "%pip install optimum==1.24.0\n",
    "%pip install openai==1.61.0\n",
    "%pip install wandb\n",
    "%pip install pydantic_settings\n",
    "%pip install json_repair==0.29.1\n",
    "%pip install accelerate==0.26.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e1666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone --depth 1 https://github.com/hiyouga/LlamaFactory.git\n",
    "!cd LlamaFactory && pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd086d6d",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11d5b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import wandb\n",
    "import torch\n",
    "import random\n",
    "import requests\n",
    "import json_repair \n",
    "from os.path import join\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "from pydantic import BaseModel,Field\n",
    "from Helper.config import get_settings\n",
    "from typing import List, Optional , Literal\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c4dc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.5.1+cu121\n",
      "CUDA: 12.1\n",
      "Available: True\n",
      "GPU: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"CUDA:\", torch.version.cuda)\n",
    "print(\"Available:\", torch.cuda.is_available())\n",
    "print(\"GPU:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642b0d2b",
   "metadata": {},
   "source": [
    "# Sittings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "57715ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json(text):\n",
    "    try:\n",
    "        return json_repair.loads(text)\n",
    "    except:\n",
    "        return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9578f02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m [wandb.login()] Changing session credentials to explicit value for https://api.wandb.ai.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\a1hmm\\_netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m⚠️  Warning: 'huggingface-cli login' is deprecated. Use 'hf auth login' instead.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `hf`CLI if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "The token `FineTuning` has been saved to C:\\Users\\a1hmm\\.cache\\huggingface\\stored_tokens\n",
      "Your token has been saved to C:\\Users\\a1hmm\\.cache\\huggingface\\token\n",
      "Login successful.\n",
      "The current active token is: `FineTuning`\n"
     ]
    }
   ],
   "source": [
    "settings = get_settings()\n",
    "wandb.login(key=settings.WANDB_API_KEY)\n",
    "!huggingface-cli login --token {settings.HUGGINGFACE_API_KEY}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e943a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"src/Data\"\n",
    "base_model_id = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "device = \"cuda\"\n",
    "torch_dtype = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe0561a",
   "metadata": {},
   "source": [
    "# Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daef6701",
   "metadata": {},
   "outputs": [],
   "source": [
    "story = \"\"\"\n",
    "ذكرت مجلة فوربس أن العائلة تلعب دورا محوريا في تشكيل علاقة الأفراد بالمال،\n",
    " حيث تتأثر هذه العلاقة بأنماط السلوك المالي المتوارثة عبر الأجيال.\n",
    "\n",
    "التقرير الذي يستند إلى أبحاث الأستاذ الجامعي شاين إنيت حول\n",
    "الرفاه المالي يوضح أن لكل شخص \"شخصية مالية\" تتحدد وفقا لطريقة\n",
    " تفاعله مع المال، والتي تتأثر بشكل مباشر بتربية الأسرة وتجارب الطفولة.\n",
    "\n",
    " الأبعاد الثلاثة للعلاقة بالمال\n",
    "بحسب الدراسة، هناك ثلاثة أبعاد رئيسية تشكّل علاقتنا بالمال:\n",
    "\n",
    "الاكتساب (A): يميل الأفراد الذين ينتمون لهذا\n",
    " البعد إلى اعتبار المال سلعة قابلة للجمع، حيث يرون\n",
    "في تحقيق الثروة هدفا بحد ذاته. والجانب السلبي لهذا\n",
    " النمط هو إمكانية التحول إلى هوس بالثروة أو العكس،\n",
    " أي رفض تام لاكتساب المال باعتباره مصدرا للفساد.\n",
    "\n",
    "الاستخدام (U): يرى هؤلاء الأشخاص المال أداة للتمتع بالحياة، حيث يربطون قيمته بقدرته على توفير\n",
    "المتعة والراحة. ومع ذلك، قد يصبح\n",
    "البعض مدمنا على الإنفاق، في حين يتجه آخرون إلى التقشف المفرط خوفا من المستقبل.\n",
    "\n",
    "الإدارة (M): أصحاب هذا النمط يعتبرون المال مسؤولية تتطلب التخطيط الدقيق. لكن في بعض الحالات،\n",
    " قد يتحول الأمر إلى هوس مفرط بإدارة الإنفاق، مما يؤثر سلبا على العلاقات الشخصية.\n",
    "\n",
    " كيف تؤثر العائلة على علاقتنا بالمال؟\n",
    "يشير التقرير إلى أن التجارب الأسرية تلعب دورا رئيسيا في تحديد\n",
    " \"الشخصية المالية\" لكل فرد، على سبيل المثال، إذا كان أحد الوالدين يعتمد على المال\n",
    "كمكافأة للسلوك الجيد، فقد يتبنى الطفل لاحقا النمط نفسه في حياته البالغة.\n",
    "\n",
    "لتحليل هذه التأثيرات بشكل دقيق، طورت رابطة العلاج المالي\n",
    "(Financial Therapy Association) أداة تسمى مخطط الجينوم المالي (Money Genogram)،\n",
    "وهو نموذج يُستخدم لتحديد الأنماط المالية داخل العائلة.\n",
    "\n",
    "تتضمن هذه الأداة:\n",
    "\n",
    "رسم شجرة عائلية.\n",
    "تصنيف أفراد العائلة وفقا للأبعاد الثلاثة للعلاقة بالمال (A ،U ،M).\n",
    "تحديد ما إذا كان السلوك المالي لكل فرد صحيا (+) أو غير صحي (-).\n",
    "على سبيل المثال، إذا نشأ شخص في عائلة\n",
    "اعتادت على الإنفاق المفرط، فقد يكون لديه ميل قوي إلى اتباع النمط نفسه،\n",
    " أو العكس تماما، حيث يصبح مقتصدا بشكل مبالغ فيه كرد فعل نفسي.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c339dac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "StoryCategory = Literal[\n",
    "    \"politics\", \"sports\", \"art\", \"technology\", \"economy\",\n",
    "    \"health\", \"entertainment\", \"science\",\n",
    "    \"not_specified\"\n",
    "]\n",
    "\n",
    "EntityType = Literal[\n",
    "    \"person-male\", \"person-female\", \"location\", \"organization\", \"event\", \"time\",\n",
    "    \"quantity\", \"money\", \"product\", \"law\", \"disease\", \"artifact\", \"not_specified\"\n",
    "]\n",
    "\n",
    "class Entity(BaseModel):\n",
    "    entity_value: str = Field(..., description=\"The actual name or value of the entity.\")\n",
    "    entity_type: EntityType = Field(..., description=\"The type of recognized entity.\")\n",
    "\n",
    "class NewsDetails(BaseModel):\n",
    "    story_title: str = Field(..., min_length=5, max_length=300,\n",
    "                             description=\"A fully informative and SEO optimized title of the story.\")\n",
    "\n",
    "    story_keywords: List[str] = Field(..., min_length=1,\n",
    "                                      description=\"Relevant keywords associated with the story.\")\n",
    "\n",
    "    story_summary: List[str] = Field(\n",
    "                                    ..., min_length=1, max_length=5,\n",
    "                                    description=\"Summarized key points about the story (1-5 points).\"\n",
    "                                )\n",
    "\n",
    "    story_category: StoryCategory = Field(..., description=\"Category of the news story.\")\n",
    "\n",
    "    story_entities: List[Entity] = Field(..., min_length=1, max_length=10,\n",
    "                                        description=\"List of identified entities in the story.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "376c87b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "details_extraction_messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\":\"\\n\".join([\n",
    "            \"You are an NLP data paraser.\",\n",
    "            \"You will be provided by an Arabic text associated with a Pydantic scheme.\",\n",
    "            \"Generate the ouptut in the same story language.\",\n",
    "            \"You have to extract JSON details from text according the Pydantic details.\",\n",
    "            \"Extract details as mentioned in text.\",\n",
    "            \"Do not generate any introduction or conclusion.\"\n",
    "\n",
    "        ])\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\\n\".join([\n",
    "            \"## Story:\",\n",
    "            story.strip(),\n",
    "            \"\",\n",
    "            \"## Pydantic Schema:\",\n",
    "            json.dumps(NewsDetails.model_json_schema(), ensure_ascii=False),\n",
    "            \"\",\n",
    "            \"## Story Details:\",\n",
    "            \"```json\",\n",
    "        ])\n",
    "    }\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1e3f1b",
   "metadata": {},
   "source": [
    "# Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8ab2ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslatedStory(BaseModel):\n",
    "    translated_title: str = Field(..., description=\"Suggested translated news story title.\")\n",
    "    translated_content: str = Field(..., description=\"Translated content of the news story \")\n",
    "\n",
    "targeted_lang = \"English\"\n",
    "\n",
    "translation_messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\":\"\\n\".join([\n",
    "            \"You are a professional translator.\",\n",
    "            \"You will be provided by an Arabic text.\",\n",
    "            \"You have to translate the text into the `Targeted Language`.\",\n",
    "            \"Follow the provided Scheme to generate a JSON\",\n",
    "            \"Do not generate any introduction or conclusion.\"\n",
    "\n",
    "        ])\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\":  \"\\n\".join([\n",
    "            \"## Story:\",\n",
    "            story.strip(),\n",
    "            \"\",\n",
    "\n",
    "            \"## Pydantic Details:\",\n",
    "            json.dumps( TranslatedStory.model_json_schema(), ensure_ascii=False ),\n",
    "            \"\",\n",
    "\n",
    "            \"## Targeted Language:\",\n",
    "            targeted_lang,\n",
    "            \"\",\n",
    "\n",
    "            \"## Translated Story:\",\n",
    "            \"```json\"\n",
    "        ])\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c220415",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6012df22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch_dtype,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3a543dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    }
   ],
   "source": [
    "text = tokenizer.apply_chat_template(\n",
    "    details_extraction_messages,\n",
    "    tokenize =False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "model_inputs = tokenizer(\n",
    "    [text],\n",
    "    return_tensors=\"pt\",    \n",
    ").to(device)\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    model_inputs.input_ids,\n",
    "    max_new_tokens=1024,\n",
    "    do_sample=False,\n",
    "    top_k= None,\n",
    "    top_p= None,\n",
    "    temperature=None,\n",
    ")\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids):]\n",
    "    for input_ids, output_ids in zip(\n",
    "        model_inputs.input_ids,\n",
    "        generated_ids\n",
    "    )\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(\n",
    "    generated_ids,\n",
    "    skip_special_tokens=True\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790ddf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0d5ef6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    }
   ],
   "source": [
    "text = tokenizer.apply_chat_template(\n",
    "    translation_messages,\n",
    "    tokenize =False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "model_inputs = tokenizer(\n",
    "    [text],\n",
    "    return_tensors=\"pt\",    \n",
    ").to(device)\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    model_inputs.input_ids,\n",
    "    max_new_tokens=1024,\n",
    "    do_sample=False,\n",
    "    top_k= None,\n",
    "    top_p= None,\n",
    "    temperature=None,\n",
    ")\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids):]\n",
    "    for input_ids, output_ids in zip(\n",
    "        model_inputs.input_ids,\n",
    "        generated_ids\n",
    "    )\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(\n",
    "    generated_ids,\n",
    "    skip_special_tokens=True\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfef1639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"translated_title\": \"Forbes Magazine: Family Plays a Central Role in Forming Individuals' Financial Relationships\",\n",
      "  \"translated_content\": \"According to Forbes magazine, family plays a crucial role in shaping individuals' financial relationships, as these relationships are influenced by inherited behavioral patterns across generations.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8673fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=settings.OPENAI_API_KEY)\n",
    "\n",
    "openai_model_id = settings.OPENAI_MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c894c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"story_title\": \"تأثير العائلة على العلاقة بالمال\",\n",
      "  \"story_keywords\": [\n",
      "    \"العائلة\",\n",
      "    \"المال\",\n",
      "    \"الشخصية المالية\",\n",
      "    \"السلوك المالي\",\n",
      "    \"الرفاه المالي\"\n",
      "  ],\n",
      "  \"story_summary\": [\n",
      "    \"تلعب العائلة دورا محوريا في تشكيل علاقة الأفراد بالمال.\",\n",
      "    \"هناك ثلاثة أبعاد رئيسية للعلاقة بالمال: الاكتساب، الاستخدام، والإدارة.\",\n",
      "    \"التجارب الأسرية تحدد 'الشخصية المالية' لكل فرد.\",\n",
      "    \"تم تطوير أداة مخطط الجينوم المالي لتحليل الأنماط المالية داخل العائلة.\"\n",
      "  ],\n",
      "  \"story_category\": \"economy\",\n",
      "  \"story_entities\": [\n",
      "    {\n",
      "      \"entity_value\": \"مجلة فوربس\",\n",
      "      \"entity_type\": \"organization\"\n",
      "    },\n",
      "    {\n",
      "      \"entity_value\": \"شاين إنيت\",\n",
      "      \"entity_type\": \"person-male\"\n",
      "    },\n",
      "    {\n",
      "      \"entity_value\": \"رابطة العلاج المالي\",\n",
      "      \"entity_type\": \"organization\"\n",
      "    },\n",
      "    {\n",
      "      \"entity_value\": \"مخطط الجينوم المالي\",\n",
      "      \"entity_type\": \"product\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "chat_messages = client.chat.completions.create(\n",
    "    messages = details_extraction_messages,\n",
    "    model=openai_model_id,\n",
    "    temperature=0.2,\n",
    ")\n",
    "print(chat_messages.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca79efec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"translated_title\": \"The Impact of Family on Financial Relationships\",\n",
      "  \"translated_content\": \"Forbes magazine stated that family plays a pivotal role in shaping individuals' relationships with money, as this relationship is influenced by inherited financial behavior patterns across generations.\\n\\nThe report, based on research by university professor Shane Enright on financial well-being, explains that each person has a \\\"financial personality\\\" determined by how they interact with money, which is directly affected by family upbringing and childhood experiences.\\n\\nThe three dimensions of the relationship with money\\nAccording to the study, there are three main dimensions that shape our relationship with money:\\n\\nAcquisition (A): Individuals belonging to this dimension tend to view money as a commodity to be accumulated, seeing wealth accumulation as a goal in itself. The downside of this pattern is the potential to develop an obsession with wealth or, conversely, a complete rejection of acquiring money as a source of corruption.\\n\\nUsage (U): These individuals see money as a tool for enjoying life, linking its value to its ability to provide pleasure and comfort. However, some may become addicted to spending, while others may resort to excessive frugality out of fear of the future.\\n\\nManagement (M): Those with this pattern consider money a responsibility that requires careful planning. However, in some cases, this can turn into an excessive obsession with managing expenses, negatively affecting personal relationships.\\n\\nHow does family influence our relationship with money?\\nThe report indicates that family experiences play a key role in determining each individual's \\\"financial personality.\\\" For example, if one parent relies on money as a reward for good behavior, the child may later adopt the same pattern in their adult life.\\n\\nTo analyze these influences accurately, the Financial Therapy Association developed a tool called the Money Genogram, which is a model used to identify financial patterns within the family.\\n\\nThis tool includes:\\n\\n- Drawing a family tree.\\n- Classifying family members according to the three dimensions of the relationship with money (A, U, M).\\n- Determining whether each individual's financial behavior is healthy (+) or unhealthy (-).\\n\\nFor instance, if a person grew up in a family accustomed to excessive spending, they may have a strong tendency to follow the same pattern, or conversely, become excessively frugal as a psychological reaction.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "chat_messages = client.chat.completions.create(\n",
    "    messages = translation_messages,\n",
    "    model=openai_model_id,\n",
    "    temperature=0.2,\n",
    ")\n",
    "print(chat_messages.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46662fe",
   "metadata": {},
   "source": [
    "# Knwoledge Distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34a9a7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows: 2400\n"
     ]
    }
   ],
   "source": [
    "data_path = \"Data/news-sample.jsonl\"\n",
    "row_data = []\n",
    "for line in open(data_path):\n",
    "    if line.strip()==\"\":\n",
    "        continue\n",
    "    row_data.append(\n",
    "        json.loads(line.strip())\n",
    "    )\n",
    "\n",
    "random.Random(101).shuffle(row_data)\n",
    "\n",
    "print(f\"Total Rows: {len(row_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580e0891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Extraction and Saving to JSONL\n",
    "price_per_1m_input_tokens = 0.150\n",
    "price_per_1m_output_tokens = 0.600\n",
    "\n",
    "prompt_tokens = 0\n",
    "completion_tokens = 0\n",
    "\n",
    "saveto_path = \"Data/sft.jsonl\"\n",
    "itr = 0\n",
    "for story in tqdm(row_data):\n",
    "    sample_details_extraction_messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\":\"\\n\".join([\n",
    "            \"You are an NLP data paraser.\",\n",
    "            \"You will be provided by an Arabic text associated with a Pydantic scheme.\",\n",
    "            \"Generate the ouptut in the same story language.\",\n",
    "            \"You have to extract JSON details from text according the Pydantic details.\",\n",
    "            \"Extract details as mentioned in text.\",\n",
    "            \"Do not generate any introduction or conclusion.\"\n",
    "\n",
    "        ])\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\\n\".join([\n",
    "            \"## Story:\",\n",
    "            story['content'].strip(),\n",
    "            \"\",\n",
    "            \"## Pydantic Schema:\",\n",
    "            json.dumps(NewsDetails.model_json_schema(), ensure_ascii=False),\n",
    "            \"\",\n",
    "            \"## Story Details:\",\n",
    "            \"```json\",\n",
    "        ])\n",
    "    }\n",
    "\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "                    messages = sample_details_extraction_messages,\n",
    "                    model=openai_model_id,\n",
    "                    temperature=0.2,\n",
    "    )\n",
    "    if response.choices[0].finish_reason != \"stop\":\n",
    "        prompt_tokens+= response.usage.prompt_tokens\n",
    "        print(\"Warning: Incomplete response detected.\")\n",
    "        continue\n",
    "\n",
    "    llm_resp_dict = response.choices[0].message.content\n",
    "    parsed_output = parse_json(llm_resp_dict)\n",
    "    if parsed_output is None:\n",
    "        continue\n",
    "\n",
    "    with open(saveto_path, \"a\", encoding=\"utf-8\") as fout:\n",
    "        fout.write(\n",
    "            json.dumps(\n",
    "                {\n",
    "                    \"story\": story['content'].strip(),\n",
    "                    \"task\": \"Extract the story details into a JSON\",\n",
    "                    \"output_schema\": json.dumps(NewsDetails.model_json_schema(), ensure_ascii=False),\n",
    "                    \"response\": llm_resp_dict,\n",
    "                },\n",
    "                ensure_ascii=False , default=str\n",
    "            )+\"\\n\"\n",
    "        )\n",
    "    itr+=1\n",
    "    prompt_tokens+= response.usage.prompt_tokens\n",
    "    completion_tokens+= response.usage.completion_tokens\n",
    "    if itr % 50 ==0:\n",
    "        cost_input = (prompt_tokens / 1000000) * price_per_1m_input_tokens\n",
    "        cost_output = (completion_tokens / 1000000) * price_per_1m_output_tokens\n",
    "        total_cost = cost_input + cost_output\n",
    "        print(f\"Processed Samples: {itr}, Total Cost: ${total_cost:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa73c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Translation and Saving to JSONL\n",
    "price_per_1m_input_tokens = 0.150\n",
    "price_per_1m_output_tokens = 0.600\n",
    "\n",
    "prompt_tokens = 0\n",
    "completion_tokens = 0\n",
    "\n",
    "save_to = join(data_dir, \"datasets\", \"sft.jsonl\")\n",
    "\n",
    "ix = 0\n",
    "for story in tqdm(row_data):\n",
    "\n",
    "    for targeted_lang in [\"English\", \"French\"]:\n",
    "        sample_translation_messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\\n\".join([\n",
    "                    \"You are a professional translator.\",\n",
    "                    \"You will be provided by an Arabic text.\",\n",
    "                    \"You have to translate the text into the `Targeted Language`.\",\n",
    "                    \"Follow the provided Scheme to generate a JSON\",\n",
    "                    \"Do not generate any introduction or conclusion.\"\n",
    "                ])\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"\\n\".join([\n",
    "                    \"## Pydantic Details:\",\n",
    "                    json.dumps( TranslatedStory.model_json_schema(), ensure_ascii=False ),\n",
    "                    \"\",\n",
    "\n",
    "                    \"## Targeted Language or Dialect:\",\n",
    "                    targeted_lang,\n",
    "                    \"\",\n",
    "\n",
    "                    \"## Story:\",\n",
    "                    story['content'].strip(),\n",
    "                    \"\",\n",
    "\n",
    "                    \"## Translated Story:\",\n",
    "                    \"```json\"\n",
    "                ])\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "                                messages=sample_translation_messages,\n",
    "                                model=openai_model_id,\n",
    "                                temperature=0.2,\n",
    "                            )\n",
    "\n",
    "        if response.choices[0].finish_reason != \"stop\":\n",
    "            prompt_tokens += response.usage.prompt_tokens\n",
    "            continue\n",
    "\n",
    "        llm_response = response.choices[0].message.content\n",
    "        llm_resp_dict = parse_json(llm_response)\n",
    "\n",
    "        if not llm_resp_dict:\n",
    "            continue\n",
    "\n",
    "        with open(save_to, \"a\", encoding=\"utf8\") as dest:\n",
    "            dest.write(json.dumps({\n",
    "                \"id\": ix,\n",
    "                \"story\": story['content'].strip(),\n",
    "\n",
    "                \"output_scheme\": json.dumps( TranslatedStory.model_json_schema(), ensure_ascii=False ),\n",
    "                \"task\": f\"You have to translate the story content into {targeted_lang} associated with a title into a JSON.\",\n",
    "\n",
    "                \"response\": llm_resp_dict,\n",
    "            }, ensure_ascii=False, default=str)  + \"\\n\" )\n",
    "\n",
    "        ix += 1\n",
    "        prompt_tokens += response.usage.prompt_tokens\n",
    "        completion_tokens += response.usage.completion_tokens\n",
    "\n",
    "        if(ix % 3) == 0:\n",
    "            cost_input = (prompt_tokens / 1_000_000) * price_per_1m_input_tokens\n",
    "            cost_output = (completion_tokens / 1_000_000) * price_per_1m_output_tokens\n",
    "            total_cost = cost_input + cost_output\n",
    "\n",
    "            print(f\"Iteration {ix}: Total Cost = ${total_cost:.4f} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2979bd12",
   "metadata": {},
   "source": [
    "# Format FineTuning Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a7a5f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sft_data_path = \"Data/sft.jsonl\"\n",
    "llm_fine_tuning_data = []\n",
    "for line in open(sft_data_path, encoding=\"utf-8\"):\n",
    "    if line.strip()==\"\":\n",
    "        continue\n",
    "    rec = json.loads(line.strip())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a57f7696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'story': 'ظلت أسعار المنتجين بالولايات المتحدة دون تغيير في سبتمبرأيلول الماضي مدفوعة بانخفاض تكاليف البنزين، مما يشير إلى تقدم نحو تضخم أقل حدة، وهو ما يدعم توقعات خفض مجلس الاحتياطي الاتحادي المركزي الأميركي أسعار الفائدة مجددا الشهر المقبل. \\n وقال مكتب إحصاءات العمل التابع لوزارة العمل -في تقرير صدر اليوم الجمعة- إن القراءة الثابتة لمؤشر أسعار المنتجين للطلب النهائي الشهر الماضي جاءت بعد زيادة غير معدلة بلغت 0.2 في أغسطسآب الماضي. وعلى أساس سنوي، ارتفع المؤشر بنسبة 1.8، وهو أقل تقدم منذ فبرايرشباط الماضي. \\n ويُظهر التقرير أن مؤشرا أقل تقلبا، يُستخدم لقياس التضخم باستثناء الغذاء والطاقة والتجارة، ارتفع بنسبة 0.1، مما يعادل أقل زيادة منذ مايوأيار 2023. في وقت ظهرت فيه البيانات الخاصة بالتضخم العام والقطاعات التي يعتمد عليها الاحتياطي الفدرالي لاتخاذ قراراته. \\n وقد استقرت تكاليف الرعاية الطبية وتكاليف الرعاية الخارجية بالمستشفيات، في حين ارتفعت أسعار تذاكر الطيران بشكل حاد. \\n توقع المتداولون أن يخفض الاحتياطي الفدرالي أسعار الفائدة ربع نقطة مئوية الشهر المقبل، بعد أن بدأ حملته لتخفيف السياسات الشهر الماضي بخفض 50 نقطة أساس. \\n ومع ذلك، قد تؤدي التقارير الأخيرة -عن زيادة الوظائف وضغوط الأسعار المستمرة- إلى تعديل هذه التوقعات. \\n وأظهر التقرير أن تكاليف الخدمات ارتفعت بنسبة 0.2، في حين قفزت أسعار المواد الغذائية بنسبة 1، وهو أعلى مستوى منذ فبرايرشباط الماضي. \\n وفي المقابل، انخفضت أسعار الطاقة بنسبة 2.7، وكذلك تكاليف السلع المُعالجة للطلب الوسيط بنسبة 0.8، بسبب التراجع الكبير في أسعار وقود الديزل.',\n",
       " 'output_scheme': '{\"$defs\": {\"Entity\": {\"properties\": {\"entity_value\": {\"description\": \"The actual name or value of the entity.\", \"title\": \"Entity Value\", \"type\": \"string\"}, \"entity_type\": {\"description\": \"The type of entity recognized.\", \"enum\": [\"person-male\", \"person-female\", \"location\", \"organization\", \"event\", \"time\", \"quantity\", \"money\", \"product\", \"law\", \"disease\", \"artifact\", \"not_specified\"], \"title\": \"Entity Type\", \"type\": \"string\"}}, \"required\": [\"entity_value\", \"entity_type\"], \"title\": \"Entity\", \"type\": \"object\"}}, \"properties\": {\"story_title\": {\"description\": \"A fully informative and SEO optimized title of the story.\", \"maxLength\": 300, \"minLength\": 5, \"title\": \"Story Title\", \"type\": \"string\"}, \"story_keywords\": {\"description\": \"Relevant keywords associated with the story.\", \"items\": {\"type\": \"string\"}, \"minItems\": 1, \"title\": \"Story Keywords\", \"type\": \"array\"}, \"story_summary\": {\"description\": \"Summarized key points about the story (1-5 points).\", \"items\": {\"type\": \"string\"}, \"maxItems\": 5, \"minItems\": 1, \"title\": \"Story Summary\", \"type\": \"array\"}, \"story_category\": {\"description\": \"Category of the news story.\", \"enum\": [\"politics\", \"sports\", \"art\", \"technology\", \"economy\", \"health\", \"entertainment\", \"science\", \"not_specified\"], \"title\": \"Story Category\", \"type\": \"string\"}, \"story_entities\": {\"description\": \"List of identified entities in the story.\", \"items\": {\"$ref\": \"#/$defs/Entity\"}, \"maxItems\": 10, \"minItems\": 1, \"title\": \"Story Entities\", \"type\": \"array\"}}, \"required\": [\"story_title\", \"story_keywords\", \"story_summary\", \"story_category\", \"story_entities\"], \"title\": \"NewsDetails\", \"type\": \"object\"}',\n",
       " 'task': 'Extrat the story details into a JSON.',\n",
       " 'response': {'story_title': 'استقرار أسعار المنتجين في الولايات المتحدة يشير إلى تضخم أقل حدة',\n",
       "  'story_keywords': ['أسعار المنتجين',\n",
       "   'التضخم',\n",
       "   'مجلس الاحتياطي الفدرالي',\n",
       "   'الولايات المتحدة',\n",
       "   'الاقتصاد'],\n",
       "  'story_summary': ['أسعار المنتجين في الولايات المتحدة لم تتغير في سبتمبر.',\n",
       "   'انخفاض تكاليف البنزين ساهم في استقرار الأسعار.',\n",
       "   'توقعات بخفض أسعار الفائدة من قبل الاحتياطي الفدرالي.',\n",
       "   'زيادة طفيفة في مؤشر أسعار المنتجين على أساس سنوي.',\n",
       "   'ارتفاع أسعار المواد الغذائية وتذاكر الطيران.'],\n",
       "  'story_category': 'economy',\n",
       "  'story_entities': [{'entity_value': 'الولايات المتحدة',\n",
       "    'entity_type': 'location'},\n",
       "   {'entity_value': 'مجلس الاحتياطي الفدرالي', 'entity_type': 'organization'},\n",
       "   {'entity_value': 'أسعار المنتجين', 'entity_type': 'product'},\n",
       "   {'entity_value': 'البنزين', 'entity_type': 'product'},\n",
       "   {'entity_value': 'أسعار الفائدة', 'entity_type': 'money'},\n",
       "   {'entity_value': 'التضخم', 'entity_type': 'disease'},\n",
       "   {'entity_value': 'تكاليف الرعاية الطبية', 'entity_type': 'money'},\n",
       "   {'entity_value': 'أسعار المواد الغذائية', 'entity_type': 'money'},\n",
       "   {'entity_value': 'أسعار تذاكر الطيران', 'entity_type': 'money'},\n",
       "   {'entity_value': 'أسعار الطاقة', 'entity_type': 'money'}]}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00755fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
